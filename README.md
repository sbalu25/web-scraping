# Web Data Scraping
The main purpose of this project is to gain an understanding of web scraping tools and to compare their performance, duration, utility, languages, and supported platforms. Specifically, the project aims to utilize different scraping tools to extract data from three social media platforms (Reddit, Twitter, and ???) and compare the results based on various data points. The ultimate goal is to determine which tool is most effective for web scraping and to provide insights on how to use these tools effectively for data mining, sentiment analysis, and other applications.
 * Selenium
Selenium is a popular open-source automated testing framework used for testing web applications. It allows developers to write test scripts in various programming languages like Python, Java, and C#. Selenium also provides a suite of software tools like Selenium IDE, Remote Control, Web Driver, and Selenium Grid. The WebDriver API acts as a communication channel between the browser and the programming language, allowing users to execute different tests on different browsers like Chrome, Firefox, and IE. The Selenium language bindings offer multiple language options for developers to interact with the Selenium server. Additionally, Selenium uses a unique driver for each browser to ensure a secure connection and support both headless and real browsers.

* Scrapy
Scrapy is an open-source web crawling platform written in Python that provides support for XPath and CSS expressions to select and extract data from sources. Scrapy's Spider class is responsible for defining how to navigate links on a website and gather data from its pages. The Scrapy engine manages data flow between all system components, while the Scheduler schedules engine requests and the Downloader program downloads web pages and delivers them to the Scrapy engine. End-users can write custom Spiders to parse and extract objects and responses. Finally, the Item Pipeline processes the extracted items. For example, to extract tweets for a hashtag or profile, users can send a request specifying the URL and use a CSS selector or XPath to retrieve specific fields like likes, replies, and post text.
* Puppeteer
Puppeteer is a Node.js library that controls Chrome/Chromium using the DevTools Protocol. It can also work with other browsers like Firefox. Puppeteer runs in headless mode by default but can run in non-headless mode as well. The library communicates with the browser through the DevTools Protocol and can create multiple browser contexts and pages. Puppeteer can be used for various tasks like web testing, scraping, and capturing screenshots. To use Puppeteer, one needs to download and import it, launch a new instance of Chromium, navigate to the desired page, perform the required action, and then exit the browser. An example of using Puppeteer is navigating to google.com, searching for a keyword, clicking on the first result, and taking a screenshot of the entire page.
* Data set description
The project involves scraping user information from popular social media sites with public APIs and lenient privacy policies, including Twitter, Facebook, and Reddit. The chosen data types for each site are user ID, post/tweet content, comments, likes/shares/upvotes, and hyperlinks or hashtags. The data collection process involves crawling and scraping the sites for the key tags and then processing the raw data into user-readable excel sheets in CSV format.
* Evaluations
The research is divided into two phases: verification and evaluation. In the verification phase, the accuracy of data extracted from one tool is compared with data taken from another tool to ensure consistency. In the evaluation phase, the tools are evaluated based on criteria such as frequency of data crawling, amount of data that can be scraped, restrictions imposed by the scraping application, consistency and accuracy of data, and ease of use. The pros and cons of each tool were identified based on the findings, such as Selenium's compatibility with different operating systems and Scrapy's limited support for JavaScript.
